{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20BIT0094 - Pranav Undre\n",
    "# 20BIT0047 - Rishabh Agrawal\n",
    "# 20BIT0368 - Neha Elagandula \n",
    "# Soft computing Image Steganography\n",
    "\n",
    "# Here we are importing all the libraries required\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import scipy.misc\n",
    "from tqdm import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset zip file\n",
    "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzipping the contents present in our database\n",
    "!unzip /content/tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are declaring the constants\n",
    "DATA_DIR = \"./tiny-imagenet-200\"\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "IMG_SHAPE = (64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_small(num_images_per_class_train=10, num_images_test=500):\n",
    "    # Here we are loading training and test datasets.\n",
    "\n",
    "    # Arguments used by us in the function are as follows:\n",
    "        # num_images_per_class_train refers to the number of images per class to load into training dataset.\n",
    "        # num_images_test refers to the total number of images to load into training dataset.\n",
    "    \n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    \n",
    "    # Here we are creating the training set.\n",
    "    for c in os.listdir(TRAIN_DIR):\n",
    "        c_dir = os.path.join(TRAIN_DIR, c, 'images')\n",
    "        c_imgs = os.listdir(c_dir)\n",
    "        random.shuffle(c_imgs)\n",
    "        for img_name_i in c_imgs[0:num_images_per_class_train]:\n",
    "            img_i = image.load_img(os.path.join(c_dir, img_name_i))\n",
    "            x = image.img_to_array(img_i)\n",
    "            X_train.append(x)\n",
    "    random.shuffle(X_train)\n",
    "    \n",
    "    # Here we are creating the test set.\n",
    "    test_dir = os.path.join(TEST_DIR, 'images')\n",
    "    test_imgs = os.listdir(test_dir)\n",
    "    random.shuffle(test_imgs)\n",
    "    for img_name_i in test_imgs[0:num_images_test]:\n",
    "        img_i = image.load_img(os.path.join(test_dir, img_name_i))\n",
    "        x = image.img_to_array(img_i)\n",
    "        X_test.append(x)\n",
    "\n",
    "    # Here we are returning the train and test data as numpy arrays.\n",
    "    return np.array(X_train), np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are loading the dataset.\n",
    "X_train_orig, X_test_orig = load_dataset_small()\n",
    "\n",
    "# Here we are normalizing the image vectors.\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Here we are printing the statistics.\n",
    "print (\"Number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"Number of test examples = \" + str(X_train.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape)) \n",
    "# The above statement will result in the output of format (train_size, 64, 64, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are splitting training set into two halfs.\n",
    "# First half is used for training as secret images and second half for cover images.\n",
    "\n",
    "# S refers to secret image\n",
    "input_S = X_train[0:X_train.shape[0] // 2]\n",
    "\n",
    "# C refers to cover image\n",
    "input_C = X_train[X_train.shape[0] // 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are displaying sample images from the training dataset.\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "columns = 4\n",
    "rows = 5\n",
    "for i in range(1, columns*rows +1):\n",
    "    # The line below will randomly sample images from training dataset and will be displayed.\n",
    "    img_idx = np.random.choice(X_train.shape[0])\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(X_train[img_idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The beta variable declared by below is used to weight the losses of the secret and cover images and its value is set based on the most feasible value \n",
    "# proposed in the papers which we encountered during literature review. \n",
    "beta = 1.0\n",
    "    \n",
    "# The function below will determine loss for reveal network\n",
    "def rev_loss(s_true, s_pred):\n",
    "    # Loss for reveal network is: beta * |S-S'|\n",
    "    return beta * K.sum(K.square(s_true - s_pred))\n",
    "\n",
    "# The function below will determine loss for the full model, which has been used for preparation and hidding networks\n",
    "def full_loss(y_true, y_pred):\n",
    "    # Loss for the full model is: |C-C'| + beta * |S-S'|\n",
    "    s_true, c_true = y_true[:,:,:,0:3], y_true[:,:,:,3:6]\n",
    "    s_pred, c_pred = y_pred[:,:,:,0:3], y_pred[:,:,:,3:6]\n",
    "    \n",
    "    s_loss = beta * K.sum(K.square(s_true - s_pred))\n",
    "    c_loss = K.sum(K.square(c_true - c_pred))\n",
    "    \n",
    "    return s_loss + c_loss\n",
    "\n",
    "\n",
    "# The function below returns the encoder as a Keras model, composed by Preparation and Hiding Networks.\n",
    "def make_encoder(input_size):\n",
    "    input_S = Input(shape=(input_size))\n",
    "    input_C= Input(shape=(input_size))\n",
    "\n",
    "    # The code below is used for generating Preparation Network\n",
    "    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='selu', name='conv_prep0_3x3')(input_S)\n",
    "    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='selu', name='conv_prep0_4x4')(input_S)\n",
    "    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='selu', name='conv_prep0_5x5')(input_S)\n",
    "    x = concatenate([x3, x4, x5])\n",
    "    \n",
    "    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='selu', name='conv_prep1_3x3')(x)\n",
    "    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='selu', name='conv_prep1_4x4')(x)\n",
    "    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='selu', name='conv_prep1_5x5')(x)\n",
    "    x = concatenate([x3, x4, x5])\n",
    "    \n",
    "    x = concatenate([input_C, x])\n",
    "    \n",
    "    # The code below is used for generating Hiding network\n",
    "    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='selu', name='conv_hid0_3x3')(x)\n",
    "    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='selu', name='conv_hid0_4x4')(x)\n",
    "    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='selu', name='conv_hid0_5x5')(x)\n",
    "    x = concatenate([x3, x4, x5])\n",
    "    \n",
    "    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='selu', name='conv_hid1_3x3')(x)\n",
    "    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='selu', name='conv_hid1_4x4')(x)\n",
    "    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='selu', name='conv_hid1_5x5')(x)\n",
    "    x = concatenate([x3, x4, x5])\n",
    "    \n",
    "    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='selu', name='conv_hid2_3x3')(x)\n",
    "    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='selu', name='conv_hid2_4x4')(x)\n",
    "    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='selu', name='conv_hid2_5x5')(x)\n",
    "    x = concatenate([x3, x4, x5])\n",
    "    \n",
    "    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='selu', name='conv_hid3_3x3')(x)\n",
    "    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='selu', name='conv_hid3_4x4')(x)\n",
    "    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='selu', name='conv_hid3_5x5')(x)\n",
    "    x = concatenate([x3, x4, x5])\n",
    "    \n",
    "    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='selu', name='conv_hid4_3x3')(x)\n",
    "    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='selu', name='conv_hid4_4x4')(x)\n",
    "    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='selu', name='conv_hid5_5x5')(x)\n",
    "    x = concatenate([x3, x4, x5])\n",
    "    \n",
    "    output_Cprime = Conv2D(3, (3, 3), strides = (1, 1), padding='same', activation='selu', name='output_C')(x)\n",
    "    \n",
    "    return Model(inputs=[input_S, input_C],\n",
    "                 outputs=output_Cprime,\n",
    "                 name = 'Encoder')\n",
    "\n",
    "# The function below returns the decoder as a Keras model, composed by the Reveal Network\n",
    "def make_decoder(input_size, fixed=False):\n",
    "    \n",
    "    # The variable declared below will store the Reveal network\n",
    "    reveal_input = Input(shape=(input_size))\n",
    "    \n",
    "    # Here we are adding Gaussian noise with 0.01 standard deviation for better training accuracy\n",
    "    input_with_noise = GaussianNoise(0.01, name='output_C_noise')(reveal_input)\n",
    "    \n",
    "    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='selu', name='conv_rev0_3x3')(input_with_noise)\n",
    "    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='selu', name='conv_rev0_4x4')(input_with_noise)\n",
    "    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='selu', name='conv_rev0_5x5')(input_with_noise)\n",
    "    x = concatenate([x3, x4, x5])\n",
    "    \n",
    "    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='selu', name='conv_rev1_3x3')(x)\n",
    "    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='selu', name='conv_rev1_4x4')(x)\n",
    "    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='selu', name='conv_rev1_5x5')(x)\n",
    "    x = concatenate([x3, x4, x5])\n",
    "    \n",
    "    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='selu', name='conv_rev2_3x3')(x)\n",
    "    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='selu', name='conv_rev2_4x4')(x)\n",
    "    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='selu', name='conv_rev2_5x5')(x)\n",
    "    x = concatenate([x3, x4, x5])\n",
    "    \n",
    "    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='selu', name='conv_rev3_3x3')(x)\n",
    "    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='selu', name='conv_rev3_4x4')(x)\n",
    "    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='selu', name='conv_rev3_5x5')(x)\n",
    "    x = concatenate([x3, x4, x5])\n",
    "    \n",
    "    x3 = Conv2D(50, (3, 3), strides = (1, 1), padding='same', activation='selu', name='conv_rev4_3x3')(x)\n",
    "    x4 = Conv2D(10, (4, 4), strides = (1, 1), padding='same', activation='selu', name='conv_rev4_4x4')(x)\n",
    "    x5 = Conv2D(5, (5, 5), strides = (1, 1), padding='same', activation='selu', name='conv_rev5_5x5')(x)\n",
    "    x = concatenate([x3, x4, x5])\n",
    "    \n",
    "    output_Sprime = Conv2D(3, (3, 3), strides = (1, 1), padding='same', activation='selu', name='output_S')(x)\n",
    "    \n",
    "    if not fixed:\n",
    "        return Model(inputs=reveal_input,\n",
    "                     outputs=output_Sprime,\n",
    "                     name = 'Decoder')\n",
    "    else:\n",
    "        return Container(inputs=reveal_input,\n",
    "                         outputs=output_Sprime,\n",
    "                         name = 'DecoderFixed')\n",
    "\n",
    "# The function below is for the Full model being used.\n",
    "def make_model(input_size):\n",
    "    input_S = Input(shape=(input_size))\n",
    "    input_C= Input(shape=(input_size))\n",
    "    \n",
    "    encoder = make_encoder(input_size)\n",
    "    \n",
    "    decoder = make_decoder(input_size)\n",
    "    decoder.compile(optimizer='adam', loss=rev_loss)\n",
    "    decoder.trainable = False\n",
    "    \n",
    "    output_Cprime = encoder([input_S, input_C])\n",
    "    output_Sprime = decoder(output_Cprime)\n",
    "\n",
    "    autoencoder = Model(inputs=[input_S, input_C],\n",
    "                        outputs=concatenate([output_Sprime, output_Cprime]))\n",
    "    autoencoder.compile(optimizer='adam', loss=full_loss)\n",
    "    \n",
    "    return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model, reveal_model, autoencoder_model = make_model(input_S.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch_idx):\n",
    "    if epoch_idx < 200:\n",
    "        return 0.001\n",
    "    elif epoch_idx < 400:\n",
    "        return 0.0003\n",
    "    elif epoch_idx < 600:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCHS = 60\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "m = input_S.shape[0]\n",
    "loss_history = []\n",
    "for epoch in range(NB_EPOCHS):\n",
    "    np.random.shuffle(input_S)\n",
    "    np.random.shuffle(input_C)\n",
    "    \n",
    "    t = tqdm(range(0, input_S.shape[0], BATCH_SIZE),mininterval=0)\n",
    "    ae_loss = []\n",
    "    rev_loss = []\n",
    "    for idx in t:\n",
    "        \n",
    "        batch_S = input_S[idx:min(idx + BATCH_SIZE, m)]\n",
    "        batch_C = input_C[idx:min(idx + BATCH_SIZE, m)]\n",
    "        \n",
    "        C_prime = encoder_model.predict([batch_S, batch_C])\n",
    "        \n",
    "        ae_loss.append(autoencoder_model.train_on_batch(x=[batch_S, batch_C],\n",
    "                                                   y=np.concatenate((batch_S, batch_C),axis=3)))\n",
    "        rev_loss.append(reveal_model.train_on_batch(x=C_prime,\n",
    "                                              y=batch_S))\n",
    "        \n",
    "        # Here we are updating the learning rate\n",
    "        K.set_value(autoencoder_model.optimizer.lr, lr_schedule(epoch))\n",
    "        K.set_value(reveal_model.optimizer.lr, lr_schedule(epoch))\n",
    "        \n",
    "        t.set_description('Epoch {} | Batch: {:3} of {}. Loss AE {:10.2f} | Loss Rev {:10.2f}'.format(epoch + 1, idx, m, np.mean(ae_loss), np.mean(rev_loss)))\n",
    "    loss_history.append(np.mean(ae_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are plotting the  loss through epochs\n",
    "plt.plot(loss_history)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are retrieving the  decoded predictions.\n",
    "decoded = autoencoder_model.predict([input_S, input_C])\n",
    "decoded_S, decoded_C = decoded[...,0:3], decoded[...,3:6]\n",
    "\n",
    "# Here we are evaluating the absolute difference between the outputs and the expected values.\n",
    "diff_S, diff_C = np.abs(decoded_S - input_S), np.abs(decoded_C - input_C) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below calculates mean of Sum of Squared Errors per pixel for cover and secret images.\n",
    "def pixel_errors(input_S, input_C, decoded_S, decoded_C):\n",
    "    see_Spixel = np.sqrt(np.mean(np.square(255*(input_S - decoded_S))))\n",
    "    see_Cpixel = np.sqrt(np.mean(np.square(255*(input_C - decoded_C))))\n",
    "    \n",
    "    return see_Spixel, see_Cpixel\n",
    "\n",
    " # The function below calculates histograms of errors for cover and secret image.\n",
    "def pixel_histogram(diff_S, diff_C):\n",
    "    diff_Sflat = diff_S.flatten()\n",
    "    diff_Cflat = diff_C.flatten()\n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    a=fig.add_subplot(1,2,1)\n",
    "        \n",
    "    imgplot = plt.hist(255* diff_Cflat, 100, density=True,  alpha=0.75, facecolor='red')\n",
    "    a.set_title('Distribution of error in the Cover image.')\n",
    "    plt.axis([0, 250, 0, 0.2])\n",
    "    \n",
    "    a=fig.add_subplot(1,2,2)\n",
    "    imgplot = plt.hist(255* diff_Sflat, 100, density=True,  alpha=0.75, facecolor='red')\n",
    "    a.set_title('Distribution of errors in the Secret image.')\n",
    "    plt.axis([0, 250, 0, 0.2])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below prints pixel-wise average errors on a 256 scale.\n",
    "S_error, C_error = pixel_errors(input_S, input_C, decoded_S, decoded_C)\n",
    "\n",
    "print (\"S error per pixel [0, 255]:\", S_error)\n",
    "print (\"C error per pixel [0, 255]:\", C_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are plotting distribution of errors in cover and secret images.\n",
    "pixel_histogram(diff_S, diff_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Function to evaluate PSNR value\n",
    "def PSNR(original, compressed):\n",
    "    mse = np.mean((original - compressed) ** 2)\n",
    "    if(mse == 0): \n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * np.math.log10(max_pixel / np.math.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "# Function to evaluate MSE value\n",
    "def mse(imageA, imageB):\n",
    "\terr = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "\terr /= float(imageA.shape[0] * imageA.shape[1])\n",
    "\treturn err\n",
    "\n",
    "\n",
    "\n",
    "# The code below shows images in gray scale\n",
    "SHOW_GRAY = False\n",
    "# The code below shows difference bettwen predictions and ground truth.\n",
    "SHOW_DIFF = True\n",
    "\n",
    "# Here we have declared Diff enhance magnitude\n",
    "ENHANCE = 1\n",
    "\n",
    "# The variable n is declared to show the Number of secret and cover pairs.\n",
    "n = 6\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "def show_image(img, n_rows, n_col, idx, gray=False, first_row=False, title=None):\n",
    "    ax = plt.subplot(n_rows, n_col, idx)\n",
    "    if gray:\n",
    "        plt.imshow(rgb2gray(img), cmap = plt.get_cmap('gray'))\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if first_row:\n",
    "        plt.title(title)\n",
    "\n",
    "plt.figure(figsize=(14, 15))\n",
    "rand_indx = [random.randint(0, 1000) for x in range(n)]\n",
    "for i, idx in enumerate(rand_indx):\n",
    "    n_col = 6 if SHOW_DIFF else 4\n",
    "    \n",
    "    img_np = np.squeeze(input_C[idx])\n",
    "    img_np1 = np.squeeze(decoded_C[idx])\n",
    "\n",
    "    kl = ssim(img_np,img_np1,multichannel=True)\n",
    "    print(f\"SSIM value is {kl}\")\n",
    "\n",
    "\n",
    "\n",
    "    original = input_C[idx]\n",
    "    compressed = decoded_C[idx]\n",
    "    value = PSNR(original, compressed)\n",
    "    print(f\"PSNR value is {value} dB\")\n",
    "\n",
    "    value1 = mse(original, compressed)\n",
    "    print(f\"MSE value is {value1}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    show_image(input_C[idx], n, n_col, i * n_col + 1, gray=SHOW_GRAY, first_row=i==0, title='Cover')\n",
    "\n",
    "    show_image(input_S[idx], n, n_col, i * n_col + 2, gray=SHOW_GRAY, first_row=i==0, title='Secret')\n",
    "    \n",
    "    show_image(decoded_C[idx], n, n_col, i * n_col + 3, gray=SHOW_GRAY, first_row=i==0, title='Encoded Cover')\n",
    "    \n",
    "    show_image(decoded_S[idx], n, n_col, i * n_col + 4, gray=SHOW_GRAY, first_row=i==0, title='Decoded Secret')\n",
    "\n",
    "  \n",
    "    if SHOW_DIFF:\n",
    "        show_image(np.multiply(diff_C[idx], ENHANCE), n, n_col, i * n_col + 5, gray=SHOW_GRAY, first_row=i==0, title='Diff Cover')\n",
    "        \n",
    "        show_image(np.multiply(diff_S[idx], ENHANCE), n, n_col, i * n_col + 6, gray=SHOW_GRAY, first_row=i==0, title='Diff Secret')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
